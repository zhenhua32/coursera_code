{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tech\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.3        0.6        0.90000004]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(linear_model, {x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(W*1+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.660002\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([0.9999908], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess.run(init) # reset values to incorrect defaults.\n",
    "for i in range(1000):\n",
    "  sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "\n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969] b: [0.9999908] loss: 5.6999738e-11\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W*x + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "# training loop\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to wrong\n",
    "for i in range(1000):\n",
    "  sess.run(train, {x: x_train, y: y_train})\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zhenh\\AppData\\Local\\Temp\\tmp8ew3ofxd\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zhenh\\\\AppData\\\\Local\\\\Temp\\\\tmp8ew3ofxd', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000294E8CDAE80>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\zhenh\\AppData\\Local\\Temp\\tmp8ew3ofxd\\model.ckpt.\n",
      "INFO:tensorflow:loss = 10.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 347.197\n",
      "INFO:tensorflow:loss = 0.09539829, step = 101 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.348\n",
      "INFO:tensorflow:loss = 0.04131108, step = 201 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.064\n",
      "INFO:tensorflow:loss = 0.010785462, step = 301 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.685\n",
      "INFO:tensorflow:loss = 0.0014749274, step = 401 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.487\n",
      "INFO:tensorflow:loss = 0.00023667383, step = 501 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.246\n",
      "INFO:tensorflow:loss = 4.477232e-05, step = 601 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.244\n",
      "INFO:tensorflow:loss = 9.5842715e-06, step = 701 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.952\n",
      "INFO:tensorflow:loss = 1.6954516e-06, step = 801 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.593\n",
      "INFO:tensorflow:loss = 3.8763613e-07, step = 901 (0.286 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\zhenh\\AppData\\Local\\Temp\\tmp8ew3ofxd\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.695453e-08.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-08-12:50:07\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\zhenh\\AppData\\Local\\Temp\\tmp8ew3ofxd\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-08-12:50:09\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.4502983e-08, global_step = 1000, loss = 5.801193e-08\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-08-12:50:09\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\zhenh\\AppData\\Local\\Temp\\tmp8ew3ofxd\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-08-12:50:11\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.0025359832, global_step = 1000, loss = 0.010143933\n",
      "train metrics: {'average_loss': 1.4502983e-08, 'loss': 5.801193e-08, 'global_step': 1000}\n",
      "eval metrics: {'average_loss': 0.0025359832, 'loss': 0.010143933, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Declare list of features. We only have one numeric feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# linear classification, and many neural network classifiers and regressors.\n",
    "# The following code provides an estimator that does linear regression.\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use two data sets: one for training and one for evaluation\n",
    "# We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the  method and passing the\n",
    "# training data set.\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zhenh\\AppData\\Local\\Temp\\tmp_y03ri0d\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zhenh\\\\AppData\\\\Local\\\\Temp\\\\tmp_y03ri0d', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000294E90C1DA0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\zhenh\\AppData\\Local\\Temp\\tmp_y03ri0d\\model.ckpt.\n",
      "INFO:tensorflow:loss = 78.17268760082351, step = 1\n",
      "INFO:tensorflow:global_step/sec: 390.545\n",
      "INFO:tensorflow:loss = 0.5965855748345507, step = 101 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.213\n",
      "INFO:tensorflow:loss = 0.02818799831205263, step = 201 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.349\n",
      "INFO:tensorflow:loss = 0.0037470932548122264, step = 301 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.946\n",
      "INFO:tensorflow:loss = 0.00019022674795542393, step = 401 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.052\n",
      "INFO:tensorflow:loss = 2.3130424932653728e-05, step = 501 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.524\n",
      "INFO:tensorflow:loss = 2.2829209209293966e-06, step = 601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.697\n",
      "INFO:tensorflow:loss = 1.4763224666856075e-07, step = 701 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.428\n",
      "INFO:tensorflow:loss = 4.94392017369796e-09, step = 801 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.812\n",
      "INFO:tensorflow:loss = 1.2874925570963066e-09, step = 901 (0.217 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\zhenh\\AppData\\Local\\Temp\\tmp_y03ri0d\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9.76251654396022e-11.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-08-12:54:09\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\zhenh\\AppData\\Local\\Temp\\tmp_y03ri0d\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-08-12:54:10\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.185896e-10\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-08-12:54:11\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\zhenh\\AppData\\Local\\Temp\\tmp_y03ri0d\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-08-12:54:12\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.010101391\n",
      "train metrics: {'loss': 1.185896e-10, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010101391, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "  # Build a linear model and predict values\n",
    "  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "  y = W*features['x'] + b\n",
    "  # Loss sub-graph\n",
    "  loss = tf.reduce_sum(tf.square(y - labels))\n",
    "  # Training sub-graph\n",
    "  global_step = tf.train.get_global_step()\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "  train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "  # EstimatorSpec connects subgraphs we built to the\n",
    "  # appropriate functionality.\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7., 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
